{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "First, you need to import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [pandas](pandas.pydata.org/) is an important package for Python data analysis.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Problem Statement ##\n",
    "\n",
    "You are given a dataset containing:\n",
    "    - a training set for a linear function\n",
    "    - a test set for testing the learned hypothesis function\n",
    "    \n",
    "You will build a simple linear regression algorithm that can correctly identify the parameters of w0 and w1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for W and initializes w_0 to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the W vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    W -- initialized vector of shape (dim, 1)\n",
    "    w_0 -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Hint: you can use np.zeros to initialize W\n",
    "    W = np.zeros(shape=(dim, 1))\n",
    "    w_0 = 0\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(W.shape == (dim, 1))\n",
    "    assert(isinstance(w_0, float) or isinstance(w_0, int))\n",
    "    return W, w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Gradient Descent ##\n",
    "\n",
    "Forward Propagation:\n",
    "- You get X\n",
    "- You compute $h_{W}(X) = W^T * X + w_{0}\\tag{1}$\n",
    "- You calculate the cost function:  $$E(W) = \\frac{1}{2m} \\sum_{i=1}^{n} \\left(h_{W}(x^{(i)})  - y^{(i)}\\right)^2\\tag{2}$$. \n",
    "\n",
    "Here are the two formulas you will be using: \n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial w_{j}} = \\frac{1}{m} \\sum_{i=1}^m (( h_{W}(x^{(i)}) -y^{(i)}) * x_{j}^{(i)})\\tag{3}$$\n",
    "$$ \\frac{\\partial E}{\\partial w_{0}} = \\frac{1}{m} \\sum_{i=1}^m (h_{W}(x^{(i)}) -y^{(i)})\\tag{4}$$\n",
    "\n",
    "The weights will be updated:\n",
    "$$ w_{j} = w_{j} - {\\alpha} * \\frac{\\partial E}{\\partial w_{j}}\\tag{5}$$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Algorithm\n",
    "\n",
    "def gradient_descent(W, w_0, X, Y, num_iterations, learning_rate, print_cost = True):\n",
    "    \"\"\"\n",
    "    This function optimizes W by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    W -- the weight vector\n",
    "    w_0 -- bias, a scalar\n",
    "    X -- data of the single feature\n",
    "    Y -- true \"label\" vector \n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You need to finish the following steps:\n",
    "        1) Calculate the cost and the gradient for the current parameters. \n",
    "        2) Update the parameters using gradient descent rule for w_0 and w_1.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    # W.shape = (2, 1)\n",
    "    # X.shape = (2, 1000)\n",
    "    # Y.shape = (1, 1000)\n",
    "    # num_iterations = 2000\n",
    "    # Get the number of training examples\n",
    "    m = X.shape[1]\n",
    "    Y_hat = np.zeros((1, m))\n",
    "    dw = np.zeros(shape=(2, 1))\n",
    "    \n",
    "    for i in range(num_iterations):      \n",
    "        \n",
    "        ### START CODE HERE ### \n",
    "        # Calculate the heuristic function: h(x) = W.T * X + w_0\n",
    "        Y_hat = w_0 + np.dot(W.T, X)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    \n",
    "        ### START CODE HERE ### \n",
    "        # Calculate cost, dw, and dw_0\n",
    "        difference = Y_hat - Y\n",
    "        cost = np.dot(difference, difference.T)/(2*m)\n",
    "        dw[0] = np.dot(difference, X[0].T)/m\n",
    "        dw[1] = np.dot(difference, X[1].T)/m\n",
    "        dw_0 = np.sum(difference)/m\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        ### START CODE HERE ### \n",
    "        # Update W and w_0\n",
    "        W = W - learning_rate * dw\n",
    "        w_0 = w_0 - learning_rate * dw_0\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        \n",
    "        if((i % 100) == 0):\n",
    "            costs.append(cost)\n",
    "            \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        \n",
    "        \n",
    "    params = {\n",
    "        \"W\": W,\n",
    "        \"w_0\": w_0\n",
    "    }\n",
    "\n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"dw_0\": dw_0\n",
    "    }\n",
    "        \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions ###\n",
    "The predicted output is calculated as $h_{W}(X) = W^T * X + w_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(W, w_0, X):\n",
    "    '''\n",
    "    Predict the real values using learned parameters (W, w_0)\n",
    "    \n",
    "    Arguments:\n",
    "    W -- weights, a numpy array of size \n",
    "    w_0 -- bias, a scalar\n",
    "    X -- data \n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    W = W.reshape(X.shape[0], 1)\n",
    "    # W: (2,1)\n",
    "    # Y_prediction: (1,1000)\n",
    "    # X_train: (2,1000) or X_test: (2,7)\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    Y_prediction = np.dot(W.T, X) + w_0\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling ###\n",
    "Here you normalize features using:\n",
    "$ \\frac{x_{i} - mean}{\\sigma}$, where $\\sigma$ is the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mtx):\n",
    "    '''\n",
    "    mtx: the matrix that needs to be normalized. Note that each column represents a training example. \n",
    "         The number of columns is the the number of training examples\n",
    "    '''\n",
    "    # Calculate mean for each feature\n",
    "    # Pay attention to the value of axis = ?\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # mtx.shape = (2,1000)\n",
    "    m = mtx.shape[1]\n",
    "    n = mtx.shape[0]\n",
    "    print(\"Normalize: mtx.shape[0]: \" + str(n))\n",
    "    print(\"Normalize: mtx.shape[1]: \" + str(m))\n",
    "    \n",
    "    mean = mtx.sum(axis = 1) / mtx.shape[1]\n",
    "    print(\"Normalize: mean orig shape: \" + str(mean.shape))\n",
    "    mean = mean.reshape(n, 1)\n",
    "    print(\"Normalize: mean reshape: \" + str(mean.shape))\n",
    "    #mean: (2,1)\n",
    "    print(\"Normalize: mean: \" + str(mean))\n",
    "    \n",
    "    std = np.ptp(mtx,axis=1)\n",
    "    print(\"Normalize: std: np.ptp: \" + str(std))\n",
    "    print(\"Normalize: std orig shape: \" + str(std.shape))\n",
    "    std = std.reshape(n, 1)\n",
    "    print(\"Normalize: std reshape: \" + str(std.shape))\n",
    "    #std: (2,1)\n",
    "    print(\"Normalize: std: \" + str(std))\n",
    "    \n",
    "    print(\"Normalize: mtx = \" + str(mtx))\n",
    "    mtx = (mtx - mean) / std\n",
    "    print(\"Normalize: normalized mtx = \" + str(mtx))\n",
    "    print(\"Normalize: normalized mtx.shape = \" + str(mtx.shape))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the linear regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array \n",
    "    Y_train -- training labels represented by a numpy array (vector) \n",
    "    X_test -- test set represented by a numpy array\n",
    "    Y_test -- test labels represented by a numpy array (vector)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    dim = X_train.shape[0]\n",
    "    # dim = 2\n",
    "    W, w_0 = initialize_with_zeros(dim)\n",
    "    \n",
    "    #X_train = normalize(X_train)\n",
    "    #X_test = normalize(X_test)\n",
    "    \n",
    "    \n",
    "    # Gradient descent \n",
    "    ### START CODE HERE ###\n",
    "    parameters, grads, costs = gradient_descent(W, w_0, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    # Retrieve parameters w and w_0 from dictionary \"parameters\"\n",
    "    W = parameters[\"W\"]\n",
    "    w_0 = parameters[\"w_0\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    ### START CODE HERE ###\n",
    "    Y_prediction_train = predict(W, w_0, X_train)\n",
    "    Y_prediction_test = predict(W, w_0, X_test)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    print(\"w is \", W)\n",
    "    print(\"w_0 is \", w_0)\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"W\" : W, \n",
    "         \"w_0\" : w_0,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Start the Learning Process ###\n",
    "You can change num_iterations and learning_rate to see the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 370.221965\n",
      "Cost after iteration 100: 0.760852\n",
      "Cost after iteration 200: 0.359170\n",
      "Cost after iteration 300: 0.181564\n",
      "Cost after iteration 400: 0.103034\n",
      "Cost after iteration 500: 0.068312\n",
      "Cost after iteration 600: 0.052959\n",
      "Cost after iteration 700: 0.046171\n",
      "Cost after iteration 800: 0.043169\n",
      "Cost after iteration 900: 0.041842\n",
      "Cost after iteration 1000: 0.041255\n",
      "Cost after iteration 1100: 0.040996\n",
      "Cost after iteration 1200: 0.040881\n",
      "Cost after iteration 1300: 0.040830\n",
      "Cost after iteration 1400: 0.040808\n",
      "Cost after iteration 1500: 0.040798\n",
      "Cost after iteration 1600: 0.040793\n",
      "Cost after iteration 1700: 0.040792\n",
      "train accuracy: 75.74912830793697 %\n",
      "test accuracy: nan %\n",
      "w is  [[3.0022454 ]\n",
      " [1.99699774]]\n",
      "w_0 is  5.601138398683342\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prj2data1.csv', header=None)\n",
    "X_train = df[[0, 1]].values.T\n",
    "Y_train = df[2].values.reshape(-1, 1).T\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('prj2data1_test.csv', header=None)\n",
    "X_test = df_test[[0, 1]].values.T\n",
    "Y_test = df_test[2].values.reshape(-1, 1).T\n",
    "\n",
    "\n",
    "d = model(X_train, Y_train, X_test, Y_test, num_iterations = 1800, learning_rate = 0.03, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learning curve ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 65591548106.457443\n",
      "Cost after iteration 100: nan\n",
      "Cost after iteration 200: nan\n",
      "Cost after iteration 300: nan\n",
      "Cost after iteration 400: nan\n",
      "Cost after iteration 500: nan\n",
      "Cost after iteration 600: nan\n",
      "Cost after iteration 700: nan\n",
      "Cost after iteration 800: nan\n",
      "Cost after iteration 900: nan\n",
      "Cost after iteration 1000: nan\n",
      "Cost after iteration 1100: nan\n",
      "Cost after iteration 1200: nan\n",
      "Cost after iteration 1300: nan\n",
      "Cost after iteration 1400: nan\n",
      "Cost after iteration 1500: nan\n",
      "Cost after iteration 1600: nan\n",
      "Cost after iteration 1700: nan\n",
      "train accuracy: nan %\n",
      "test accuracy: nan %\n",
      "w is  [[nan]\n",
      " [nan]]\n",
      "w_0 is  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('prj2house.csv', header=None)\n",
    "X_train = df[[0, 1]].values.T\n",
    "Y_train = df[2].values.reshape(-1, 1).T\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('prj2house_test.csv', header=None)\n",
    "X_test = df_test[[0, 1]].values.T\n",
    "Y_test = df_test[2].values.reshape(-1, 1).T\n",
    "\n",
    "\n",
    "d = model(X_train, Y_train, X_test, Y_test, num_iterations = 1800, learning_rate = 0.01, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcIklEQVR4nO3de5hddX3v8fdHYsAEQhIZEESIQU28VAwO0lSNaDyAVqtirForELUxtqQt1qM5xQtK7aOip8ZyIMZooo8R0SCKqKHoEfFSghNyAZIgGMDMwchAEOSiMfA5f6wVWezsucDMmslkfV7Ps57svdZvr/397YH9Wdfflm0iIqK5HjfSBURExMhKEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCKIRJH1P0qkjXUfEnihBELWSdIukl490HbZfYfuLI10HgKQrJL1jGN5nX0lfkHSPpG2S3t1P+zPKdneXr9u3suxsSddK2inprLprj+GVIIhRT9KYka5hlz2pFuAs4OnAkcBLgfdKOqldQ0knAguB2cAUYCrw4UqTm4D3At+pr9wYKQmCGDGSXiVpnaTfSvqZpOdWli2U9EtJv5O0UdLrKstOk/RTSf8haTtwVjnvJ5I+KekuSTdLekXlNX/aCh9A26dKurJ87+9L+j+SvtxLH46X1C3pfZK2AcskTZJ0qaSecv2XSjq8bP9R4MXAuZLulXRuOX+6pMslbZd0g6S/HoKP+BTgbNt32d4EfA44rZe2pwKft3297buAs6ttbX/R9veA3w1BXbGHSRDEiJB0DPAF4J3AE4HPApdUDkf8kuIL80CKLdMvSzq0sorjgC3AwcBHK/NuAA4CPgF8XpJ6KaGvtl8Bri7rOgt4az/deRIwmWLLex7F/1fLyudHAA8A5wLYPhP4MXC67f1tny5pPHB5+b4HA28GzpP07HZvJum8MjzbTRvKNpOAw4D1lZeuB9qus5zf2vYQSU/sp++xFxiVQVAev7xd0nUDaDtL0jXlsc05LctOlXRjOeVE4vD6O+CztlfbfrA8fv8H4M8BbH/d9m22H7J9IXAj8ILK62+z/Z+2d9p+oJx3q+3P2X4Q+CJwKHBIL+/ftq2kI4BjgQ/a3mH7J8Al/fTlIeBDtv9g+wHbd9q+yPb9tn9HEVQv6eP1rwJusb2s7M81wEXAnHaNbf+97Ym9TLv2qvYv/7278tK7gQN6qWH/Nm3po33sRUZlEADLgbbHOtv4FcUu7leqMyVNBj5EsWX4AuBD5VZUDI8jgX+pbs0CT6HYikXSKZXDRr8FnkOx9b7L1jbr3Lbrge37y4f7t2nXV9vDgO2Veb29V1WP7d/veiJpnKTPSrpV0j3AlcBESfv08vojgeNaPou3UOxpPFb3lv9OqMybQO+Hdu5t05Y+2sdeZFQGge0rge3VeZKOkrRK0hpJP5Y0vWx7i+0NFFttVScCl9veXh4TvZyBh0sM3lbgoy1bs+NsXyDpSIrj2acDT7Q9EbgOqB7mqWvY3F8DkyWNq8x7Sj+vaa3lX4BpwHG2JwCzyvnqpf1W4Ectn8X+tt/V7s0kLS7PL7Sbrgco/5v+NXB05aVHA9f30ofr27T9je07e+927C1GZRD0YgmwwPbzgfcA5/XT/sk8ckuvu5wXQ+/xkvarTGMovujnSzpOhfGS/lLSAcB4ii/LHgBJcyn2CGpn+1agi+IE9FhJM4FXP8rVHEBxXuC3lT3Pqt9QXJWzy6XAMyS9VdLjy+lYSc/spcb5ZVC0m6rnAL4EvL88eT2d4nDc8l5q/hLwdknPKveM319tW9a0H8V3xpjy79jbHk6MMntFEEjaH/gL4OuS1lGceDy071fR7iRifpyhHt+l+GLcNZ1lu4vii+lc4C6KyxNPA7C9EfgU8N8UX5p/Bvx0GOt9CzATuBP4N+BCivMXA/Vp4AnAHcBVwKqW5YuAOeUVRZ8pzyOcALwJuI3isNXHgX0ZnA9RnHS/FfgRcI7tVQCSjij3II4AKOd/Avhh2f5WHhlgn6P4270ZOLN83N9J9BglNFp/mEbSFOBS28+RNAG4wXavX/6SlpftV5bP3wwcb/ud5fPPAlfYvqDu2mN0kXQhsNl265Z9xF5hr9gjsH0PcLOkNwCUhxqO7udllwEnlLvNkyi2yC6rudQYBcrDMkdJepyKG7BeA3xzpOuKqMuoDAJJF1AcNpim4maet1Pszr9d0nqKE1+vKdseK6kbeAPw2crJtO0UN838vJw+Us6LeBJwBcWVNJ8B3mV77YhWFFGjUXtoKCIihsao3COIiIihsycNkDUgBx10kKdMmTLSZUREjCpr1qy5w3ZHu2WjLgimTJlCV1fXSJcRETGqSLq1t2U5NBQR0XC1BoGkiZJWStosaVN5l2Z1+SRJF0vaIOlqScNy92hERDys7j2CRcAq29Mpxi7Z1LL8X4F15YiJp5TtIyJiGNUWBOXdvrOAzwOUQ/r+tqXZs4AflMs3A1Mk9TZscERE1KDOPYKpFIOGLZO0VtJSFT/AUbUeOBlA0gsohuM9vHVFkuZJ6pLU1dPTU2PJERHNU2cQjAGOAc63PQO4j+I3Uas+BkwqB4pbAKwFdrauyPYS2522Ozs62l79FBERj1Gdl492A922V5fPV9ISBOUYQXOhGB8IuLmcIiJimNS2R2B7G7BV0rRy1mxgY7VNeVXR2PLpO4Ary3CIiIhhUvcNZQuAFeWX/RZgrqT5ALYXA88EviTpQYqQeHvN9URERItag8D2OqCzZfbiyvL/Bp5eZw0REdG33FkcEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ1XaxBImihppaTNkjZJmtmy/EBJ35a0XtL1kubWWU9EROxuTM3rXwSssj1H0lhgXMvyfwA22n61pA7gBkkrbO+oua6IiCjVFgSSJgCzgNMAyi/31i94AwdIErA/sB3YWVdNERGxuzoPDU0FeoBlktZKWippfEubc4FnArcB1wL/ZPuh1hVJmiepS1JXT09PjSVHRDRPnUEwBjgGON/2DOA+YGFLmxOBdcBhwPOAc8s9iUewvcR2p+3Ojo6OGkuOiGieOoOgG+i2vbp8vpIiGKrmAt9w4SbgZmB6jTVFRESL2oLA9jZgq6Rp5azZwMaWZr8q5yPpEGAasKWumiIiYnd1XzW0AFhRXjG0BZgraT6A7cXA2cBySdcCAt5n+46aa4qIiIpag8D2OqCzZfbiyvLbgBPqrCEiIvqWO4sjIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLgEQUREwyUIIiIaLkEQEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouFqDQJJEyWtlLRZ0iZJM1uW/09J68rpOkkPSppcZ00REfFIY2pe/yJgle05ksYC46oLbZ8DnAMg6dXAGba311xTRERU1BYEkiYAs4DTAGzvAHb08ZI3AxfUVU9ERLRX56GhqUAPsEzSWklLJY1v11DSOOAk4KIa64mIiDbqDIIxwDHA+bZnAPcBC3tp+2rgp70dFpI0T1KXpK6enp56qo2IaKg6g6Ab6La9uny+kiIY2nkTfRwWsr3Edqftzo6OjiEuMyKi2WoLAtvbgK2SppWzZgMbW9tJOhB4CfCtumqJiIje1X3V0AJgRXnF0BZgrqT5ALYXl21eB/yX7ftqriUiItqoNQhsrwM6W2YvbmmzHFheZx0REdG73FkcEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLhag0DSREkrJW2WtEnSzDZtjpe0TtL1kn5UZz0REbG7MTWvfxGwyvYcSWOBcdWFkiYC5wEn2f6VpINrriciIlrUFgSSJgCzgNMAbO8AdrQ0+xvgG7Z/Vba5va56IiKivToPDU0FeoBlktZKWippfEubZwCTJF0haY2kU9qtSNI8SV2Sunp6emosOSKieeoMgjHAMcD5tmcA9wEL27R5PvCXwInAByQ9o3VFtpfY7rTd2dHRUWPJERHNU2cQdAPdtleXz1dSBENrm1W277N9B3AlcHSNNUVERIvagsD2NmCrpGnlrNnAxpZm3wJeLGmMpHHAccCmumqKiIjdDSgIJL1hIPPaWACskLQBeB7w75LmS5oPYHsTsArYAFwNLLV93UCLj4iIwZPt/htJ19g+pr95w6Gzs9NdXV3D/bYREaOapDW2O9st6/PyUUmvAF4JPFnSZyqLJgA7h67EiIgYKf3dR3Ab0AX8FbCmMv93wBl1FRUREcOnzyCwvR5YL+krtv8IIGkS8BTbdw1HgRERUa+BXjV0uaQJkiYD6yluEvvfNdYVERHDZKBBcKDte4CTgWW2nw+8vL6yIiJiuAw0CMZIOhT4a+DSGuuJiIhhNtAg+AhwGfBL2z+XNBW4sb6yIiJiuAxo9FHbXwe+Xnm+BXh9XUVFRMTwGeidxYdLuljS7ZJ+I+kiSYfXXVxERNRvoIeGlgGXAIcBTwa+Xc6LiIhRbqBB0GF7me2d5bQcyHjQERF7gYEGwR2S/lbSPuX0t8CddRYWERHDY6BB8DaKS0e3Ab8G5gBz6yoqIiKGz0B/s/hs4NRdw0qUdxh/kiIgIiJiFBvoHsFzq2ML2d4OzKinpIiIGE4DDYLHlYPNAX/aIxjo3kREROzBBvpl/ingZ5JWAqY4X/DR2qqKiIhhM9A7i78kqQt4GSDgZNutvz8cERGj0IAP75Rf/Pnyj4jYywz0HEFEROylEgQREQ1XaxBImihppaTNkjZJmtmy/HhJd0taV04frLOeiIjYXd2XgC4CVtmeI2ksMK5Nmx/bflXNdURERC9qCwJJE4BZwGkAtncAO+p6v4iIeGzqPDQ0Feih+KH7tZKWShrfpt1MSeslfU/Ss9utSNI8SV2Sunp6emosOSKieeoMgjHAMcD5tmcA9wELW9pcAxxp+2jgP4FvtluR7SW2O213dnRk9OuIiKFUZxB0A922V5fPV1IEw5/Yvsf2veXj7wKPl3RQjTVFRESL2oLA9jZgq6Rp5azZtNyQJulJklQ+fkFZT37nICJiGNV91dACYEV5xdAWYK6k+QC2F1P8rsG7JO0EHgDeZNs11xQRERUabd+7nZ2d7urqGukyIiJGFUlrbHe2W5Y7iyMiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLgEQUREwyUIIiIaLkEQEdFwCYKIiIZLEERENFyCICKi4WoNAkkTJa2UtFnSJkkze2l3rKQHJc2ps56IiNjdmJrXvwhYZXuOpLHAuNYGkvYBPg5cVnMtERHRRm17BJImALOAzwPY3mH7t22aLgAuAm6vq5aIiOhdnYeGpgI9wDJJayUtlTS+2kDSk4HXAYv7WpGkeZK6JHX19PTUV3FERAPVGQRjgGOA823PAO4DFra0+TTwPtsP9rUi20tsd9ru7OjoqKfaiIiGqvMcQTfQbXt1+XwluwdBJ/BVSQAHAa+UtNP2N2usKyIiKmoLAtvbJG2VNM32DcBsYGNLm6fueixpOXBpQiAiYnjVfdXQAmBFecXQFmCupPkAtvs8LxAREcOj1iCwvY7i8E9V2wCwfVqdtURERHu5szgiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLgEQUREwyUIIiIaLkEQEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGq7WIJA0UdJKSZslbZI0s2X5ayRtkLROUpekF9VZT0RE7G5MzetfBKyyPUfSWGBcy/IfAJfYtqTnAl8DptdcU0REVNQWBJImALOA0wBs7wB2VNvYvrfydDzguuqJiIj26jw0NBXoAZZJWitpqaTxrY0kvU7SZuA7wNvarUjSvPLQUVdPT0+NJUdENE+dQTAGOAY43/YM4D5gYWsj2xfbng68Fji73YpsL7Hdabuzo6OjxpIjIpqnziDoBrptry6fr6QIhrZsXwkcJemgGmuKiIgWtQWB7W3AVknTylmzgY3VNpKeJknl42OAscCdddUUERG7q/uqoQXAivKKoS3AXEnzAWwvBl4PnCLpj8ADwBtt54RxRMQw0mj73u3s7HRXV9dIlxERMapIWmO7s92y3FkcEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ1XaxBImihppaTNkjZJmtmy/C2SNpTTzyQdXWc9ERGxuzE1r38RsMr2HEljgXEty28GXmL7LkmvAJYAx9VcU0REVNQWBJImALOA0wBs7wB2VNvY/lnl6VXA4XXVExER7dV5aGgq0AMsk7RW0lJJ4/to/3bge+0WSJonqUtSV09PTx21RkQ0lmzXs2Kpk2Ir/4W2V0taBNxj+wNt2r4UOA94ke07+1lvD3BrHTXX7CDgjpEuYpilz3u/pvUXRm+fj7Td0W5BnecIuoFu26vL5yuBha2NJD0XWAq8or8QAOitI3s6SV22O0e6juGUPu/9mtZf2Dv7XNuhIdvbgK2SppWzZgMbq20kHQF8A3ir7V/UVUtERPSu7quGFgAryiuGtgBzJc0HsL0Y+CDwROA8SQA797akjYjY09UaBLbXAa1f7Isry98BvKPOGvYgS0a6gBGQPu/9mtZf2Av7XNvJ4oiIGB0yxERERMMlCCIiGi5BMIQkTZZ0uaQby38n9dLu1LLNjZJObbP8EknX1V/x4A2mz5LGSfpOORbV9ZI+NrzVD5ykkyTdIOkmSe0ug95X0oXl8tWSplSW/a9y/g2SThzOugfjsfZZ0v+QtEbSteW/Lxvu2h+rwfydy+VHSLpX0nuGq+YhYTvTEE3AJ4CF5eOFwMfbtJlMcQXVZGBS+XhSZfnJwFeA60a6P3X3mWLsqZeWbcYCP6a4n2TE+9VS/z7ALynulh8LrAee1dLm74HF5eM3AReWj59Vtt8XeGq5nn1Guk8193kGcFj5+DnA/xvp/tTd58ryi4CvA+8Z6f48mil7BEPrNcAXy8dfBF7bps2JwOW2t9u+C7gcOAlA0v7Au4F/G4Zah8pj7rPt+23/EP40FtU17JnjTb0AuMn2lrLOr1L0u6r6OawEZqu4Jvo1wFdt/8H2zcBN5fr2dI+5z7bX2r6tnH89sJ+kfYel6sEZzN8ZSa+l2Mi5fpjqHTIJgqF1iO1fA5T/HtymzZOBrZXn3eU8gLOBTwH311nkEBtsn4FiyHLg1cAPaqpzMPqtv9rG9k7gbop7ZAby2j3RYPpc9Xpgre0/1FTnUHrMfS7HUXsf8OFhqHPI1X1D2V5H0veBJ7VZdOZAV9FmniU9D3ia7TNajzuOtLr6XFn/GOAC4DO2tzz6CmvXZ/39tBnIa/dEg+lzsVB6NvBx4IQhrKtOg+nzh4H/sH1vuYMwqiQIHiXbL+9tmaTfSDrU9q8lHQrc3qZZN3B85fnhwBXATOD5km6h+LscLOkK28czwmrs8y5LgBttf3oIyq1DN/CUyvPDgdt6adNdBtuBwPYBvnZPNJg+I+lw4GLgFNu/rL/cITGYPh8HzJH0CWAi8JCk39s+t/6yh8BIn6TYmybgHB554vQTbdpMpvhBnknldDMwuaXNFEbPyeJB9ZnifMhFwONGui999HEMxbHfp/LwScRnt7T5Bx55EvFr5eNn88iTxVsYHSeLB9PniWX71490P4arzy1tzmKUnSwe8QL2poni+OgPgBvLf3d92XUCSyvt3kZx0vAmYG6b9YymIHjMfabY4jKwCVhXTu8Y6T710s9XAr+guKrkzHLeR4C/Kh/vR3G1yE3A1cDUymvPLF93A3vgVVFD3Wfg/cB9lb/pOuDgke5P3X/nyjpGXRBkiImIiIbLVUMREQ2XIIiIaLgEQUREwyUIIiIaLkEQEdFwCYKohaSflf9OkfQ3Q7zuf233XnWR9FpJH6xp3ffWtN7jJV06yHUslzSnj+WnS5o7mPeIPUOCIGph+y/Kh1OARxUEkvbpp8kjgqDyXnV5L3DeYFcygH7Vrrwbdqh8AfjHIVxfjJAEQdSisqX7MeDFktZJOkPSPpLOkfRzSRskvbNsf7ykH0r6CnBtOe+b5Xj210uaV877GPCEcn0rqu+lwjmSrivHwn9jZd1XSFpZ/vbBisqIkR+TtLGs5ZNt+vEM4A+27yifL5e0WNKPJf1C0qvK+QPuV5v3+Kik9ZKuknRI5X3mVNrcW1lfb305qZz3E4rhzHe99ixJSyT9F/ClPmqVpHPLz+M7VAYQbPc52b4fuEXSaBhNNfqQsYaibgsp7rLc9YU5D7jb9rEqhib+afkFBcUwwM9xMVwzwNtsb5f0BODnki6yvVDS6baf1+a9TgaeBxwNHFS+5spy2QyK4R5uA34KvFDSRuB1wHTbVjECaqsXUgyPXTUFeAlwFPBDSU8DTnkU/aoaD1xl+8xynJq/o/9hyNv1pQv4HPAyirteL2x5zfOBF9l+oI+/wQxgGvBnwCHARuALkib38Tl1AS+muMs2RqnsEcRwOwE4RdI6YDXFEBVPL5dd3fJl+Y+S1gNXUQz09XT69iLgAtsP2v4N8CPg2Mq6u20/RDHkwRTgHuD3wFJJJ9N++O9DgZ6WeV+z/ZDtGynGppn+KPtVtQPYdSx/TVlXf9r1ZTpws+0bXQwX8OWW11xi+4HycW+1zuLhz+824P+W7fv6nG4HDhtAzbEHyx5BDDcBC2xf9oiZ0vEU49NUn78cmGn7fklXUIzz0t+6e1MdD/9BYIztneVhjdkUA4idTrFFXfUAxQiTVa3jsuwabrrffrXxRz88zsuDPPz/5E7KDbXy0M/YvvrSS11V1Rp6q/WV7dbRz+e0H8VnFKNY9giibr8DDqg8vwx4l6THQ3EMXsWPerQ6ELirDIHpwJ9Xlv1x1+tbXAm8sTwG3kGxhdvrIQsVvwh3oO3vAv9McVip1SbgaS3z3iDpcZKOovhZwxseRb8G6haKwzlQ/CpWu/5WbQaeWtYE8OY+2vZW65XAm8rP71DgpeXyvj6nZwCj4ve1o3fZI4i6bQB2lod4lgOLKA5lXFNu6fbQ/uctVwHzJW2g+KK9qrJsCbBB0jW231KZfzHF7zqsp9iyfa/tbWWQtHMA8C1J+1FsJZ/Rps2VwKckqbLlfgPFYadDgPm2fy9p6QD7NVCfK2u7mmJU1772KihrmAd8R9IdwE8ofi+4nd5qvZhiS/9aihE4f1S27+tzeiGj9Fe54mEZfTSiH5IWAd+2/X1Jy4FLba8c4bJGnKQZwLttv3Wka4nByaGhiP79OzBupIvYAx0EfGCki4jByx5BRETDZY8gIqLhEgQREQ2XIIiIaLgEQUREwyUIIiIa7v8Do7QyIyPMLpkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
